#%% md
# Health Sound Analysis using HeAR Embeddings

This notebook demonstrates how to use the HeAR model to analyze cough sounds and determine if a person might be sick.

#%% md
## Install dependencies
#%%
! pip install --upgrade --quiet transformers==4.50.3 scikit-learn==1.3.2 joblib

# Clone the HeAR repository if needed
import os
if not os.path.exists('hear'):
    ! git clone https://github.com/Google-Health/hear.git
#%%
from huggingface_hub.utils import HfFolder

if HfFolder.get_token() is None:
    from huggingface_hub import notebook_login
    notebook_login()
#%% md
## Load the Health Classifier
#%%
import sys
sys.path.append('.')  # Add current directory to path
from health_classifier import HealthClassifier
import numpy as np
from scipy.io import wavfile
from IPython.display import Audio, display
import matplotlib.pyplot as plt

# Initialize the classifier
classifier = HealthClassifier()
#%% md
## Download example audio files
#%%
import requests
import os

# Download files if they don't exist
def download_file(url, filename):
    if not os.path.exists(filename):
        print(f"Downloading {filename}...")
        response = requests.get(url)
        with open(filename, 'wb') as f:
            f.write(response.content)
        print(f"Downloaded {filename}")
    else:
        print(f"File {filename} already exists")

# Example audio files (using the Wikimedia file as the 'unhealthy' example)
download_file("https://upload.wikimedia.org/wikipedia/commons/b/be/Woman_coughing_three_times.wav", "unhealthy.wav")

# For this example, we'll assume healthy.wav already exists or you've recorded your own
# If you don't have a healthy sample, you can use:
# - Another audio file with no coughing
# - A recording of normal breathing
if not os.path.exists("healthy.wav"):
    print("Warning: healthy.wav not found. Please create this file with a healthy audio sample.")

#%% md
## Create a simple dataset for training
#%%
# Prepare file lists for training
# In a real application, you would need a larger dataset of labeled audio samples

healthy_files = []
if os.path.exists("healthy.wav"):
    healthy_files.append("healthy.wav")
else:
    print("Warning: No healthy audio files found for training")

unhealthy_files = []
if os.path.exists("unhealthy.wav"):
    unhealthy_files.append("unhealthy.wav")
else:
    print("Warning: No unhealthy audio files found for training")

# Display what we have
print(f"Healthy files: {healthy_files}")
print(f"Unhealthy files: {unhealthy_files}")

# Listen to the files
if healthy_files:
    sample_rate, audio = wavfile.read(healthy_files[0])
    print(f"\nHealthy audio sample: {healthy_files[0]}")
    display(Audio(audio, rate=sample_rate))

if unhealthy_files:
    sample_rate, audio = wavfile.read(unhealthy_files[0])
    print(f"\nUnhealthy audio sample: {unhealthy_files[0]}")
    display(Audio(audio, rate=sample_rate))

#%% md
## Train the classifier
#%%
# Note: For a real application, you need many more examples
# This is just a proof of concept with minimal data
if healthy_files and unhealthy_files:
    print("Training classifier...")
    accuracy = classifier.train(healthy_files, unhealthy_files, save_path="health_classifier_model.joblib")
    print(f"Training complete with accuracy: {accuracy:.4f}")
else:
    print("Cannot train classifier without both healthy and unhealthy audio samples")
#%% md
## Analyze new audio samples
#%%
# Function to analyze an audio file
def analyze_audio_file(file_path):
    print(f"Analyzing {file_path}...")
    
    # Load audio
    sample_rate, audio = wavfile.read(file_path)
    
    # Visualize the audio
    plt.figure(figsize=(12, 4))
    plt.plot(audio)
    plt.title(f"Waveform: {os.path.basename(file_path)}")
    plt.xlabel("Samples")
    plt.ylabel("Amplitude")
    plt.grid(True)
    plt.show()
    
    # Play the audio
    display(Audio(audio, rate=sample_rate))
    
    # Generate HeAR embedding
    embedding = classifier.generate_embedding(audio, sample_rate)
    
    # Visualize the embedding
    plt.figure(figsize=(12, 4))
    plt.plot(embedding)
    plt.title('HeAR Embedding Vector')
    plt.xlabel('Index')
    plt.ylabel('Value')
    plt.grid(True)
    plt.show()
    
    # Make prediction
    try:
        result = classifier.predict(audio, sample_rate)
        print(f"Prediction: {result['status']} (Confidence: {result['confidence']:.4f})")
        return result
    except ValueError as e:
        print(f"Error: {e}")
        return None

# Analyze the files we have
if os.path.exists("healthy.wav"):
    print("\nAnalyzing known healthy sample:")
    healthy_result = analyze_audio_file("healthy.wav")

if os.path.exists("unhealthy.wav"):
    print("\nAnalyzing known unhealthy sample:")
    unhealthy_result = analyze_audio_file("unhealthy.wav")

#%% md
## Record and analyze your own audio
#%%
def record_audio(duration=2, sample_rate=16000, filename="recorded_audio.wav"):
    """
    Record audio from microphone (if available)
    """
    try:
        import sounddevice as sd
        from scipy.io.wavfile import write
        
        print(f"Recording {duration} seconds of audio...")
        recording = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1)
        sd.wait()  # Wait until recording is finished
        write(filename, sample_rate, recording)  # Save as WAV file
        print(f"Recording saved to {filename}")
        
        # Return the recording for immediate analysis
        return recording.flatten()
    except Exception as e:
        print(f"Error recording audio: {e}")
        print("Please install sounddevice: pip install sounddevice")
        return None

# Optional: Uncomment to record and analyze your own audio
# If you have a microphone, you can use this to test your own sounds
"""
try:
    # Record audio
    your_audio = record_audio(duration=2, filename="your_audio.wav")
    
    if your_audio is not None:
        # Analyze the recording
        print("\nAnalyzing your audio sample:")
        your_result = analyze_audio_file("your_audio.wav")
except Exception as e:
    print(f"Error in recording or analysis: {e}")
"""
#%% md
## Limitations and Future Improvements

This demonstration has significant limitations:

1. **Limited training data**: For a reliable classifier, you would need hundreds or thousands of labeled examples.
2. **Simple classifier**: We used a basic random forest. More sophisticated methods might work better.
3. **No medical validation**: This is not a medical tool and has not been clinically validated.
4. **Health detection is complex**: Respiratory sounds are just one signal; real health assessment requires multiple inputs.

Future improvements:
- Collect a larger, diverse dataset of healthy and sick cough sounds
- Implement more advanced models (e.g., neural networks)
- Add time-based analysis for longitudinal health tracking
- Combine with other health indicators for more accurate assessment
